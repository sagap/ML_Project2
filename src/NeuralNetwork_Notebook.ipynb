{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv1D, Embedding, Activation, Flatten\n",
    "from keras.optimizers import Adam, SGD\n",
    "import numpy as np\n",
    "import re\n",
    "import preprocessing as preproc\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import helpers\n",
    "import models\n",
    "from tqdm import tqdm\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, y, test_data = helpers.get_processed_data(full_dataset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=None, ngram_range=(1,2), sublinear_tf=True, max_features=500)\n",
    "X = vectorizer.fit_transform(train_data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.03, beta_1=0.9, beta_2=0.99, epsilon=None, decay=0.001, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = SGD(lr=0.04, momentum=0.08, decay=0.001, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500000, 500)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=64, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "model = create_model()\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2125000 samples, validate on 375000 samples\n",
      "Epoch 1/3\n",
      " - 148s - loss: 0.4608 - acc: 0.7722 - val_loss: 0.4503 - val_acc: 0.7788\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.77877, saving model to ../data/intermediate/weights-improvement-01-0.78.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45028, saving model to ../data/intermediate/weights-improvement-01-0.45.hdf5\n",
      "Epoch 2/3\n",
      " - 148s - loss: 0.4490 - acc: 0.7810 - val_loss: 0.4472 - val_acc: 0.7813\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.77877 to 0.78125, saving model to ../data/intermediate/weights-improvement-02-0.78.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.45028 to 0.44721, saving model to ../data/intermediate/weights-improvement-02-0.45.hdf5\n",
      "Epoch 3/3\n",
      " - 148s - loss: 0.4465 - acc: 0.7826 - val_loss: 0.4456 - val_acc: 0.7822\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.78125 to 0.78218, saving model to ../data/intermediate/weights-improvement-03-0.78.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.44721 to 0.44562, saving model to ../data/intermediate/weights-improvement-03-0.45.hdf5\n"
     ]
    }
   ],
   "source": [
    "result = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=32, verbose=2, \n",
    "                  callbacks=helpers.checkpointing())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = KFold(n_splits=4, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1875000 samples, validate on 625000 samples\n",
      "Epoch 1/1\n",
      " - 138s - loss: 0.4624 - acc: 0.7708 - val_loss: 0.4540 - val_acc: 0.7761\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.77607, saving model to ../data/intermediate/weights-improvement-01-0.78.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45396, saving model to ../data/intermediate/weights-improvement-01-0.45.hdf5\n",
      "Train on 1875000 samples, validate on 625000 samples\n",
      "Epoch 1/1\n",
      " - 137s - loss: 0.4538 - acc: 0.7765 - val_loss: 0.4503 - val_acc: 0.7793\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.77934, saving model to ../data/intermediate/weights-improvement-01-0.78.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45032, saving model to ../data/intermediate/weights-improvement-01-0.45.hdf5\n",
      "Train on 1875000 samples, validate on 625000 samples\n",
      "Epoch 1/1\n",
      " - 138s - loss: 0.4523 - acc: 0.7776 - val_loss: 0.4485 - val_acc: 0.7809\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.78094, saving model to ../data/intermediate/weights-improvement-01-0.78.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44847, saving model to ../data/intermediate/weights-improvement-01-0.45.hdf5\n",
      "Train on 1875000 samples, validate on 625000 samples\n",
      "Epoch 1/1\n",
      " - 137s - loss: 0.4509 - acc: 0.7786 - val_loss: 0.4488 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.77980, saving model to ../data/intermediate/weights-improvement-01-0.78.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44884, saving model to ../data/intermediate/weights-improvement-01-0.45.hdf5\n",
      "Train on 1875000 samples, validate on 625000 samples\n",
      "Epoch 1/1\n",
      " - 138s - loss: 0.4502 - acc: 0.7793 - val_loss: 0.4485 - val_acc: 0.7797\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.77972, saving model to ../data/intermediate/weights-improvement-01-0.78.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44852, saving model to ../data/intermediate/weights-improvement-01-0.45.hdf5\n",
      "Train on 1875000 samples, validate on 625000 samples\n",
      "Epoch 1/1\n",
      " - 137s - loss: 0.4501 - acc: 0.7790 - val_loss: 0.4473 - val_acc: 0.7816\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.78164, saving model to ../data/intermediate/weights-improvement-01-0.78.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44733, saving model to ../data/intermediate/weights-improvement-01-0.45.hdf5\n",
      "Train on 1875000 samples, validate on 625000 samples\n",
      "Epoch 1/1\n",
      " - 138s - loss: 0.4501 - acc: 0.7791 - val_loss: 0.4462 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.78198, saving model to ../data/intermediate/weights-improvement-01-0.78.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44616, saving model to ../data/intermediate/weights-improvement-01-0.45.hdf5\n",
      "Train on 1875000 samples, validate on 625000 samples\n",
      "Epoch 1/1\n",
      " - 137s - loss: 0.4493 - acc: 0.7798 - val_loss: 0.4473 - val_acc: 0.7808\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.78081, saving model to ../data/intermediate/weights-improvement-01-0.78.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44731, saving model to ../data/intermediate/weights-improvement-01-0.45.hdf5\n",
      "Train on 1875000 samples, validate on 625000 samples\n",
      "Epoch 1/1\n",
      " - 138s - loss: 0.4488 - acc: 0.7800 - val_loss: 0.4475 - val_acc: 0.7805\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.78046, saving model to ../data/intermediate/weights-improvement-01-0.78.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44745, saving model to ../data/intermediate/weights-improvement-01-0.45.hdf5\n",
      "Train on 1875000 samples, validate on 625000 samples\n",
      "Epoch 1/1\n",
      " - 137s - loss: 0.4490 - acc: 0.7797 - val_loss: 0.4463 - val_acc: 0.7822\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.78220, saving model to ../data/intermediate/weights-improvement-01-0.78.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44634, saving model to ../data/intermediate/weights-improvement-01-0.45.hdf5\n",
      "Train on 1875000 samples, validate on 625000 samples\n",
      "Epoch 1/1\n",
      " - 138s - loss: 0.4491 - acc: 0.7796 - val_loss: 0.4451 - val_acc: 0.7824\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.78239, saving model to ../data/intermediate/weights-improvement-01-0.78.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44508, saving model to ../data/intermediate/weights-improvement-01-0.45.hdf5\n",
      "Train on 1875000 samples, validate on 625000 samples\n",
      "Epoch 1/1\n",
      " - 137s - loss: 0.4485 - acc: 0.7803 - val_loss: 0.4471 - val_acc: 0.7812\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.78118, saving model to ../data/intermediate/weights-improvement-01-0.78.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44710, saving model to ../data/intermediate/weights-improvement-01-0.45.hdf5\n",
      "Train on 1875000 samples, validate on 625000 samples\n",
      "Epoch 1/1\n",
      " - 138s - loss: 0.4484 - acc: 0.7803 - val_loss: 0.4464 - val_acc: 0.7810\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.78102, saving model to ../data/intermediate/weights-improvement-01-0.78.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44636, saving model to ../data/intermediate/weights-improvement-01-0.45.hdf5\n",
      "Train on 1875000 samples, validate on 625000 samples\n",
      "Epoch 1/1\n",
      " - 138s - loss: 0.4486 - acc: 0.7799 - val_loss: 0.4460 - val_acc: 0.7826\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.78264, saving model to ../data/intermediate/weights-improvement-01-0.78.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44597, saving model to ../data/intermediate/weights-improvement-01-0.45.hdf5\n",
      "Train on 1875000 samples, validate on 625000 samples\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        result = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1, batch_size=32, verbose=2, \n",
    "                  callbacks=helpers.checkpointing())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = model.fit_generator(generator=helpers.batch_generator(X_train, y_train, 32),\n",
    "#                    epochs=10, validation_data=(X_test,y_test),\n",
    "#                     steps_per_epoch=int(X_train.shape[0]/32), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.780731555556827"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(result.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../data/intermediate/weights-improvement-03-0.78.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = batch_generator(X,y,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best model so far\n",
    "adam = Adam(lr=0.02, beta_1=0.9, beta_2=0.99, epsilon=None, decay=0.001, amsgrad=False)\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
