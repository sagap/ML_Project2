{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv1D, Embedding, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import re\n",
    "import preprocessing as preproc\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import helpers\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc.do_preprocessing('../data/twitter-datasets/train_pos.txt')\n",
    "preproc.do_preprocessing('../data/twitter-datasets/train_neg.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines, y = preproc.return_processed_trainset_and_y(False)\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines1 = lines[:10000] + lines[100000:110000]\n",
    "y1 = np.concatenate((y[:10000], y[100000:110000]), axis=0)\n",
    "y1 = y1.tolist()\n",
    "print(len(lines1))\n",
    "print(len(y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=None, ngram_range=(1,2), sublinear_tf=True, max_features=1000)\n",
    "# X = vectorizer.fit(lines)\n",
    "# X = X.todense()\n",
    "# X = X.transform(lines)\n",
    "X = vectorizer.fit_transform(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.02, beta_1=0.9, beta_2=0.99, epsilon=None, decay=0.001, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 64)                64064     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 66,177\n",
      "Trainable params: 66,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "# model.add(Embedding(X.shape[0], 300, input_length=X.shape[1]))\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(units=64, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200000/200000 [==============================] - 27s 134us/step - loss: 0.4521 - acc: 0.7777\n",
      "Epoch 2/100\n",
      "200000/200000 [==============================] - 26s 129us/step - loss: 0.4212 - acc: 0.7977\n",
      "Epoch 3/100\n",
      "200000/200000 [==============================] - 26s 130us/step - loss: 0.4093 - acc: 0.8049\n",
      "Epoch 4/100\n",
      "200000/200000 [==============================] - 27s 133us/step - loss: 0.4012 - acc: 0.8098\n",
      "Epoch 5/100\n",
      "200000/200000 [==============================] - 28s 138us/step - loss: 0.3955 - acc: 0.8135\n",
      "Epoch 6/100\n",
      "200000/200000 [==============================] - 27s 133us/step - loss: 0.3912 - acc: 0.8163\n",
      "Epoch 7/100\n",
      "200000/200000 [==============================] - 26s 132us/step - loss: 0.3886 - acc: 0.8173\n",
      "Epoch 8/100\n",
      "200000/200000 [==============================] - 26s 130us/step - loss: 0.3857 - acc: 0.8198\n",
      "Epoch 9/100\n",
      "200000/200000 [==============================] - 26s 131us/step - loss: 0.3833 - acc: 0.8211\n",
      "Epoch 10/100\n",
      "200000/200000 [==============================] - 26s 131us/step - loss: 0.3818 - acc: 0.8220\n",
      "Epoch 11/100\n",
      "200000/200000 [==============================] - 26s 131us/step - loss: 0.3799 - acc: 0.8228\n",
      "Epoch 12/100\n",
      "200000/200000 [==============================] - 26s 131us/step - loss: 0.3784 - acc: 0.8241\n",
      "Epoch 13/100\n",
      "200000/200000 [==============================] - 26s 131us/step - loss: 0.3767 - acc: 0.8252\n",
      "Epoch 14/100\n",
      "200000/200000 [==============================] - 27s 135us/step - loss: 0.3753 - acc: 0.8258\n",
      "Epoch 15/100\n",
      "200000/200000 [==============================] - 34s 171us/step - loss: 0.3745 - acc: 0.8266\n",
      "Epoch 16/100\n",
      "200000/200000 [==============================] - 30s 148us/step - loss: 0.3736 - acc: 0.8272\n",
      "Epoch 17/100\n",
      "200000/200000 [==============================] - 32s 162us/step - loss: 0.3723 - acc: 0.8273\n",
      "Epoch 18/100\n",
      "200000/200000 [==============================] - 29s 146us/step - loss: 0.3713 - acc: 0.8285\n",
      "Epoch 19/100\n",
      "200000/200000 [==============================] - 26s 130us/step - loss: 0.3710 - acc: 0.8282\n",
      "Epoch 20/100\n",
      "200000/200000 [==============================] - 29s 144us/step - loss: 0.3698 - acc: 0.8289\n",
      "Epoch 21/100\n",
      "200000/200000 [==============================] - 27s 135us/step - loss: 0.3695 - acc: 0.8292\n",
      "Epoch 22/100\n",
      "200000/200000 [==============================] - 30s 148us/step - loss: 0.3689 - acc: 0.8301\n",
      "Epoch 23/100\n",
      "200000/200000 [==============================] - 36s 181us/step - loss: 0.3690 - acc: 0.8297\n",
      "Epoch 24/100\n",
      "200000/200000 [==============================] - 27s 133us/step - loss: 0.3674 - acc: 0.8306\n",
      "Epoch 25/100\n",
      "200000/200000 [==============================] - 26s 131us/step - loss: 0.3667 - acc: 0.8303\n",
      "Epoch 26/100\n",
      "200000/200000 [==============================] - 26s 131us/step - loss: 0.3667 - acc: 0.8310\n",
      "Epoch 27/100\n",
      "200000/200000 [==============================] - 27s 136us/step - loss: 0.3665 - acc: 0.8309\n",
      "Epoch 28/100\n",
      " 67456/200000 [=========>....................] - ETA: 23s - loss: 0.3635 - acc: 0.8314"
     ]
    }
   ],
   "source": [
    "#fit the model\n",
    "model.fit(x=X, y=y, batch_size=32, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X, y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generator=batch_generator(X, y1, 32),\n",
    "                   epochs=5, validation_data=(X,y1),\n",
    "                    steps_per_epoch=X.shape[0]/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size):\n",
    "    samples_per_epoch = X.shape[0]\n",
    "    num_of_batches = samples_per_epoch / batch_size\n",
    "    counter = 0\n",
    "    index = np.arange(np.shape(y)[0])\n",
    "    while True:\n",
    "        index_batch = index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[index_batch,:].toarray()\n",
    "        y_batch = y[y.index[index_batch]]\n",
    "        counter += 1\n",
    "        yield X_batch, y_batch\n",
    "        if counter > num_of_batches:\n",
    "            counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "400 features\n",
    "Me 10000 data:\n",
    "# 78.35 Adam:decay 0.002 lr 0.05 epochs 100\n",
    "# 73 Adam:decay 0.02\n",
    "\n",
    "Me 20000 data:\n",
    "# 77.23 Adam:decay 0.002 lr 0.05 epochs 100\n",
    "\n",
    "Me 200000 data:\n",
    "# 78.22 Adam:decay 0.002 lr 0.05 epochs 100\n",
    "\n",
    "Ola\n",
    "\n",
    " 78.94% adam = Adam(lr=0.02, beta_1=0.9, beta_2=0.99, epsilon=None, decay=0.001, amsgrad=False)\n",
    " \n",
    " 79.40% adam = Adam(lr=0.02, beta_1=0.9, beta_2=0.99, epsilon=None, decay=0.0001, amsgrad=False)\n",
    " \n",
    "Features 1000\n",
    "\n",
    " 81% adam = Adam(lr=0.03, beta_1=0.9, beta_2=0.99, epsilon=None, decay=0.0001, amsgrad=False)\n",
    "  \n",
    " 83 % adam = Adam(lr=0.02, beta_1=0.9, beta_2=0.99, epsilon=None, decay=0.0001, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
