{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load('../twitter-datasets/embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = {}\n",
    "with open('../twitter-datasets/vocab_cut.txt', 'r') as vocab_in:\n",
    "    vocab_lines = vocab_in.readlines()\n",
    "    line_counter = 0\n",
    "    for line in vocab_lines:\n",
    "        vocab_dict[line.replace('\\n', '')] = embeddings[line_counter]\n",
    "        line_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_path = '../twitter-datasets/train_pos.txt'\n",
    "train_neg_path = '../twitter-datasets/train_neg.txt'\n",
    "with open(train_pos_path, 'r') as pos_in, open(train_neg_path, 'r') as neg_in:\n",
    "    pos_lines = pos_in.readlines()\n",
    "    neg_lines = neg_in.readlines()\n",
    "    pos_tweets = []\n",
    "    neg_tweets = []\n",
    "    line_counter = 0\n",
    "    for pos_line in pos_lines:\n",
    "        tweet = pos_line.replace('\\n', '').split(' ')\n",
    "        tweet_features = np.array\n",
    "        for token in tweet:\n",
    "            if token in vocab_dict:\n",
    "                tweet_features = np.concatenate((tweet_features, vocab_dict[token]), axis=None)\n",
    "        try:\n",
    "            pos_tweets.append(tweet_features[1:], line_counter)\n",
    "        except:\n",
    "            None\n",
    "        line_counter += 1\n",
    "    \n",
    "    line_counter = 0        \n",
    "    for neg_line in neg_lines:\n",
    "        tweet = neg_line.replace('\\n', '').split(' ')\n",
    "        tweet_features = np.array\n",
    "        for token in tweet:\n",
    "            if token in vocab_dict:\n",
    "                tweet_features = np.concatenate((tweet_features, vocab_dict[token]), axis=None)\n",
    "        try:\n",
    "            neg_tweets.append(tweet_features[1:], line_counter)\n",
    "        except:\n",
    "            None\n",
    "        line_counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99995"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99996"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
