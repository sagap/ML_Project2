{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import text_representation as repre\n",
    "import helpers\n",
    "import preprocessing as preproc\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc.do_preprocessing('../twitter-datasets/train_pos.txt')\n",
    "preproc.do_preprocessing('../twitter-datasets/train_neg.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "embeddings = repre.load_embeddings()\n",
    "vocab_dict = repre.create_dict_from_provided_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_path = '../twitter-datasets/train_pos_processed.txt'\n",
    "pos_features = repre.create_tweet_features(train_pos_path, vocab_dict, shape_of_word_embeddings=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg_path = '../twitter-datasets/train_neg_processed.txt'\n",
    "neg_features = repre.create_tweet_features(train_neg_path, vocab_dict, shape_of_word_embeddings=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_features = pos_features[1:]\n",
    "neg_features = neg_features[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_shape = pos_features.shape[0]\n",
    "neg_shape = neg_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack((pos_features, neg_features))\n",
    "y = np.zeros(shape=(pos_features.shape[0] + neg_features.shape[0]))\n",
    "y[:pos_shape] = 1\n",
    "y[pos_shape:] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99985"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "Elapsed time: 3 min 22 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "elapsed_time = divmod(round((time.time() - start_time)), 60)\n",
    "print('------\\nElapsed time: {m} min {s} sec\\n'.format(m=elapsed_time[0], s=elapsed_time[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs = ShuffleSplit(n_splits=4, test_size=.25, random_state=0)\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5992 (+/- 0.0033)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X, y, cv=kf)\n",
    "print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### LOAD TEST SET AND PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc.do_preprocessing('../twitter-datasets/test_data.txt', test_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processed_path = '../twitter-datasets/test_data_processed.txt'\n",
    "test_features = repre.create_test_tweet_features(test_processed_path, vocab_dict, shape_of_word_embeddings=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 20)\n"
     ]
    }
   ],
   "source": [
    "test_features = test_features[1:]\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "helpers.create_submission_csv(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../twitter-datasets/train_pos.txt') as pos_in, open(\n",
    "                            '../twitter-datasets/train_neg.txt') as neg_in:\n",
    "    pos_lines = pos_in.readlines()\n",
    "    neg_lines = neg_in.readlines()\n",
    "    pos_in.close()\n",
    "    neg_in.close()\n",
    "lines = pos_lines + neg_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros(shape=(len(lines)))\n",
    "y[:len(pos_lines)] = 1\n",
    "y[len(pos_lines):] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['15', 'about', 'and', 'battle', 'because', 'believe', 'bestest', 'birthday', 'box', 'brother', 'but', 'casper', 'crakkbitch', 'crop', 'doin', 'don', 'dumb', 'dunno', 'eveerrr', 'even', 'follow', 'gift', 'god', 'hope', 'in', 'is', 'just', 'justin', 'keep', 'knows', 'lil', 'logic', 'looved', 'mama', 'me', 'mention', 'my', 'name', 'not', 'only', 'or', 'out', 'photo', 'put', 'read', 'sir', 'so', 'thang', 'thanks', 'that', 'the', 'tmr', 'trip', 'tsk', 'url', 'user', 'visiting', 'will', 'won', 'ya', 'you', 'your']\n",
      "(5, 62)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This document is the second document.',\n",
    "     'And this is the third one.',\n",
    "     'Is this the first document?',\n",
    "]\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(pos_lines[:5])\n",
    "print(vectorizer.get_feature_names())\n",
    "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=True, use_idf=True, max_features=None,\n",
    "                             stop_words='english', norm= 'l2', ngram_range=(1,1), sublinear_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  1.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_trees = []\n",
    "num_of_trees = list(range(10, 500, 50))\n",
    "for trees in num_of_trees:\n",
    "    forest = RandomForestClassifier(n_estimators=trees, random_state=4, n_jobs=-1)\n",
    "    print('Running RF ' + str(trees) + ' trees...')\n",
    "    forest.fit(X_train, y_train)\n",
    "    y_pred = forest.predict(X_validation)\n",
    "    diff = metrics.accuracy_score(y_validation, y_pred)\n",
    "    scores_trees.append(diff)\n",
    "    print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
